{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uber Rider Data Case Study\n",
    "\n",
    "December 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Project overview\n",
    "\n",
    "Uber is interested in predicting rider retention. To help explore this question, they have provided a sample dataset of a cohort of users who signed up for an account in January 2014. The data was pulled several months later. \n",
    "\n",
    "## Dataset description\n",
    "\n",
    "- city: city this user signed up in\n",
    "- phone: primary device for this user\n",
    "- signup_date: date of account registration; in the form ‘YYYY­MM­DD’\n",
    "- last_trip_date: the last time this user completed a trip; in the form ‘YYYY­MM­DD’ \n",
    "- avg_dist: the average distance *(in miles) per trip taken in the first 30 days after signup \n",
    "- avg_rating_by_driver: the rider’s average rating over all of their trips \n",
    "- avg_rating_of_driver: the rider’s average rating of their drivers over all of their trips \n",
    "- surge_pct: the percent of trips taken with surge multiplier > 1\n",
    "- avg_surge: The average surge multiplier over all of this user’s trips \n",
    "- trips_in_first_30_days: the number of trips this user took in the first 30 days after signing up\n",
    "- luxury_car_user: True if the user took an luxury car in their first 30 days; False otherwise\n",
    "- weekday_pct: the percent of the user’s trips occurring during a weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and browse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data from file\n",
    "df = pd.read_csv('data/churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Browse dataset\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show summary stats\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count missing values by column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['avg_dist'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['avg_surge'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['surge_pct'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['weekday_pct'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['avg_rating_by_driver'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['avg_rating_of_driver'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['trips_in_first_30_days'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Use scatter_matrix from Pandas\n",
    "# from pandas.tools.plotting import scatter_matrix\n",
    "# scatter_matrix(df[[u'avg_dist', u'avg_rating_by_driver', u'avg_rating_of_driver', u'avg_surge', u'surge_pct', u'trips_in_first_30_days', u'weekday_pct']],\n",
    "#                alpha=0.2, figsize=(16, 16), diagonal='hist')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Use scatter_matrix from Pandas\n",
    "# from pandas.tools.plotting import scatter_matrix\n",
    "# scatter_matrix(df[[u'avg_dist', u'trips_in_first_30_days', u'weekday_pct']], \n",
    "#                alpha=0.2, figsize=(8, 8), diagonal='kde')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['city'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['phone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['phone'].value_counts(dropna=False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['luxury_car_user'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data - dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count missing values by column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: drop all rows that have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_dropna = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dropna.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dropna.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a copy of df, because you don't want to mess up with orignal df when you experiment stuff\n",
    "df_fillna = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill missing value for phone\n",
    "df_fillna['phone'] = df['phone'].fillna('no_phone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill missing values with median\n",
    "df_fillna['avg_rating_by_driver'] = df['avg_rating_by_driver'].fillna(df['avg_rating_by_driver'].median())\n",
    "df_fillna['avg_rating_of_driver'] = df['avg_rating_of_driver'].fillna(df['avg_rating_of_driver'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_fillna.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_fillna.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision\n",
    "We need to decide whether we should exclude data with missing value. We need statistical tools to help us decide. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For now we will move on (to be revisited)\n",
    "df = df_fillna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert time-series information to datetime data type\n",
    "df['last_trip_date'] = pd.to_datetime(df['last_trip_date'])\n",
    "df['signup_date'] = pd.to_datetime(df['signup_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct a new df to experiment on the time-series \n",
    "df_timestamp = df[['last_trip_date', 'signup_date']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_timestamp['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_timestamp = df_timestamp.set_index('signup_date')\n",
    "df_timestamp['count'].resample(\"1D\").sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_timestamp = df_timestamp.set_index('last_trip_date')\n",
    "df_timestamp['count'].resample(\"1D\").sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment block\n",
    "date_in_string = '2014-06-01'\n",
    "date_in_datetime = pd.to_datetime(date_in_string)\n",
    "print date_in_datetime\n",
    "print date_in_datetime.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There might be some signal from day of week when a user signed up Uber, so let's create a column for that\n",
    "df['signup_dow'] = df['signup_date'].apply(lambda x: x.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables:\n",
    "* city\n",
    "* phone\n",
    "* luxury_car_user\n",
    "* signup_dow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert bool columns to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['luxury_car_user'] = df['luxury_car_user'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode categorical columns to numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_category = ['signup_dow', 'city', 'phone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df[col_category], columns=col_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.join(df_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a label/target/outcome\n",
    "\n",
    "Add churn indicator. Considered to churn if have not taken a trip in the last 30 days. In practice, you will often have to figure out how to generate a reasonable label to train your dataset. Is the cutoff of 30 days reasonable?  You may want to test this... Sometimes, the correct label is even less obvious; your ability to make a sensible (and defensible) decision in these cases is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define churn: users did not take a trip during last 30 days, i.e. last trip date is earlier than 2014-06-01\n",
    "df['churn'] = (df.last_trip_date < pd.to_datetime('2014-06-01')) * 1\n",
    "df['active'] = (df.last_trip_date >= pd.to_datetime('2014-06-01')) * 1\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['churn'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['active'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA with label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### colored scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = ['red' if ix else 'blue' for ix in df['active']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatter_matrix(df[[u'avg_dist', u'avg_rating_by_driver', u'avg_rating_of_driver', \n",
    "#                   u'avg_surge', u'surge_pct', u'trips_in_first_30_days', u'weekday_pct']],\n",
    "#                alpha=0.2, figsize=(16, 16), diagonal='hist', c=colors)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore churn rate split by features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[['city', 'churn']].groupby(['city']).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['phone', 'churn']].groupby(['phone']).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['luxury_car_user', 'active']].groupby(['luxury_car_user']).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['trips_in_first_30_days', 'active']].groupby(['active']).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_active = df['active'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].hist(df[is_active]['avg_dist'].values)\n",
    "axes[1].hist(df[~is_active]['avg_dist'].values)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract out the plotting machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hist_active_vs_churn(df, col_name):\n",
    "    is_active = df['active'] == 1\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "    axes[0].hist(df[is_active][col_name].values)\n",
    "    axes[0].set_title(\"active users\")\n",
    "    axes[0].set_xlabel(col_name)\n",
    "    axes[0].set_ylabel(\"counts\")\n",
    "    axes[1].hist(df[~is_active][col_name].values)\n",
    "    axes[1].set_title(\"churned users\")\n",
    "    axes[1].set_xlabel(col_name)\n",
    "    axes[1].set_ylabel(\"counts\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist_active_vs_churn(df, col_name=u'avg_rating_by_driver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = [u'avg_dist', u'avg_rating_by_driver', u'avg_rating_of_driver', u'avg_surge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    hist_active_vs_churn(df, col_name=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cleaned data to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select which columns to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_columns = [u'avg_dist', u'avg_rating_by_driver', u'avg_rating_of_driver', u'avg_surge', \n",
    "                     u'surge_pct', u'trips_in_first_30_days', u'luxury_car_user', \n",
    "                     u'weekday_pct', u'city_Astapor', u'city_King\\'s Landing',u'city_Winterfell', \n",
    "                     u'phone_Android', u'phone_iPhone', u'phone_no_phone', u'signup_dow_0', \n",
    "                     u'signup_dow_1', u'signup_dow_2', u'signup_dow_3', u'signup_dow_4', \n",
    "                     u'signup_dow_5', u'signup_dow_6', u'churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_data_csv = 'data/cleaned_data.csv'\n",
    "df[selected_columns].to_csv(cleaned_data_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload data from cleaned csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cleaned_data_csv = 'data/cleaned_data.csv'\n",
    "df = pd.read_csv(cleaned_data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features = [u'avg_dist', u'avg_rating_by_driver', u'avg_rating_of_driver', u'avg_surge', \n",
    "                     u'surge_pct', u'trips_in_first_30_days', u'luxury_car_user', \n",
    "                     u'weekday_pct', u'city_Astapor', u'city_King\\'s Landing',u'city_Winterfell', \n",
    "                     u'phone_Android', u'phone_iPhone', u'phone_no_phone', u'signup_dow_0', \n",
    "                     u'signup_dow_1', u'signup_dow_2', u'signup_dow_3', u'signup_dow_4', \n",
    "                     u'signup_dow_5', u'signup_dow_6']\n",
    "target = u'churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[selected_features].values\n",
    "y = df['churn'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use our own implementation of Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from my_LogisticRegression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from my_LogisticRegression import log_likelihood, log_likelihood_gradient, predict, predict_proba\n",
    "from my_LogisticRegression import GradientAscent\n",
    "from my_LogisticRegression import precision, accuracy, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ga = GradientAscent(cost=log_likelihood, \n",
    "                    gradient=log_likelihood_gradient, \n",
    "                    predict_func=predict,\n",
    "                    fit_intercept=True)\n",
    "ga.run(X, y, alpha=0.1, num_iterations=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_cost(cost_history, ax, alpha=1.0):\n",
    "    \"\"\"Plot the in sample cost of a gradient ascent run over time.\"\"\"\n",
    "    ax.plot(range(len(cost_history)), cost_history, alpha=alpha)\n",
    "    ax.set_title(\"Logistic Regression Cost Function Over Time\")\n",
    "    ax.set_xlabel(\"Iteration Number\")\n",
    "    ax.set_ylabel(\"Cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14, 3))\n",
    "\n",
    "plot_cost(ga.cost_history, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ga.cost_history[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use standardized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ga = GradientAscent(cost=log_likelihood, \n",
    "                    gradient=log_likelihood_gradient, \n",
    "                    predict_func=predict,\n",
    "                    fit_intercept=True)\n",
    "ga.run(X, y, alpha=0.1, num_iterations=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14, 3))\n",
    "\n",
    "plot_cost(ga.cost_history, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = ga.predict(X)\n",
    "\n",
    "print(\"The predicted class vector is \\n{}\".format(str(y_pred)))\n",
    "print(\"The actual class vector is \\n{}\".format(str(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy of the Logistic Regression is: {}\".format(accuracy(y, y_pred)))\n",
    "print(\"Precision of the Logistic Regression is: {}\".format(precision(y, y_pred)))\n",
    "print(\"Recall of the Logistic Regression is: {}\".format(recall(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Estimated Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ga.coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(selected_features, ga.coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_coeffs = pd.DataFrame(list(zip(selected_features, ga.coeffs))).sort_values(by=[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_coeffs.columns = ['feature', 'coeff']\n",
    "df_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = df_coeffs.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = df_coeffs.plot.barh()\n",
    "t = np.arange(X.shape[1])\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_coeffs['feature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to interpret coefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Recall: Increasing the value of $x_i$ by 1 increases the odds ratio by a factor of $e^{\\beta_i}$***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say, for a given user, assume he has a probability to churn at 50%, or in another word, the odd ratio is 1:1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_OR = 1 # 50% chance to churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a coefficient is 0.2, then, if we increase the corresponding variable by 1 unit, the new odd ratio will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta = 0.2\n",
    "increase = np.exp(beta)\n",
    "OR = default_OR * increase\n",
    "OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is can be converted to chance to churn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = OR / (1 + OR)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a coefficient is -0.4, then, if we increase the corresponding variable by 1 unit, the new odd ratio will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta = -0.4\n",
    "increase = np.exp(beta) * 1\n",
    "OR = default_OR * increase\n",
    "OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is can be converted to chance to churn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = OR / (1 + OR)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the result with our EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['luxury_car_user', 'churn']].groupby(['churn']).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['luxury_car_user', 'churn']].groupby(['luxury_car_user']).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['avg_dist', 'churn']].groupby(['churn']).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['phone_iPhone', 'churn']].groupby(['churn']).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['avg_rating_by_driver', 'churn']].groupby(['churn']).mean().plot.bar()\n",
    "plt.legend(loc='lower center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Logistic Regression from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=100000, fit_intercept=True)\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X)\n",
    "print(\"Accuracy of the Logistic Regression is: {}\".format(accuracy(y, y_pred)))\n",
    "print(\"Precision of the Logistic Regression is: {}\".format(precision(y, y_pred)))\n",
    "print(\"Recall of the Logistic Regression is: {}\".format(recall(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_coeffs = pd.DataFrame(list(zip(selected_features, lr.coef_.flatten()))).sort_values(by=[1], ascending=False)\n",
    "df_coeffs.columns = ['feature', 'coeff']\n",
    "df_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = df_coeffs.plot.barh()\n",
    "t = np.arange(X.shape[1])\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_coeffs['feature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use polynomial features - high orders!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_poly = PolynomialFeatures(degree=2, interaction_only=True).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=1000000, fit_intercept=True)\n",
    "lr.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_poly)\n",
    "print(\"Accuracy of the Logistic Regression is: {}\".format(accuracy(y, y_pred)))\n",
    "print(\"Precision of the Logistic Regression is: {}\".format(precision(y, y_pred)))\n",
    "print(\"Recall of the Logistic Regression is: {}\".format(recall(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.shape, y_train.shape\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.1, fit_intercept=True)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred = lr.predict(X_train)\n",
    "print(\"Training score:\")\n",
    "print(\"Accuracy of the Logistic Regression is: {}\".format(accuracy(y_train, y_train_pred)))\n",
    "print(\"Precision of the Logistic Regression is: {}\".format(precision(y_train, y_train_pred)))\n",
    "print(\"Recall of the Logistic Regression is: {}\".format(recall(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = lr.predict(X_test)\n",
    "print(\"Test score:\")\n",
    "print(\"Accuracy of the Logistic Regression is: {}\".format(accuracy(y_test, y_test_pred)))\n",
    "print(\"Precision of the Logistic Regression is: {}\".format(precision(y_test, y_test_pred)))\n",
    "print(\"Recall of the Logistic Regression is: {}\".format(recall(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    '''\n",
    "    Code from sklearn example.\n",
    "    '''\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    # Show confusion matrix in a separate window\n",
    "    plt.matshow(cm)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, lr.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "\n",
    "# 45 degree line\n",
    "xx = np.linspace(0, 1.0, 20)\n",
    "plt.plot(xx, xx, color='red')\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Area Under Curve (AUC) of the Logistic Regression is: {}\".format(roc_auc_score(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall-Precision Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prec, rec, thresholds = precision_recall_curve(y_test, lr.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(rec, prec)\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Recall-Precision Curve\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Profit Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def standard_confusion_matrix(y_true, y_predict):\n",
    "    [[tn, fp], [fn, tp]] = confusion_matrix(y_true, y_predict)\n",
    "    return np.array([[tp, fp], [fn, tn]])\n",
    "\n",
    "def profit_curve(cost_benefit_matrix, probabilities, y_true):\n",
    "    thresholds = sorted(probabilities, reverse=True)\n",
    "    profits = []\n",
    "    for threshold in thresholds:\n",
    "        y_predict = probabilities > threshold\n",
    "        confusion_mat = standard_confusion_matrix(y_true, y_predict)\n",
    "        profit = np.sum(confusion_mat * cost_benefit_matrix) / float(len(y_true))\n",
    "        profits.append(profit)\n",
    "    return thresholds, profits\n",
    "\n",
    "def run_profit_curve(model, costbenefit, X_train, X_test, y_train, y_test):\n",
    "    probabilities = model.predict_proba(X_test)[:, 1]\n",
    "    thresholds, profits = profit_curve(costbenefit, probabilities, y_test)\n",
    "    return thresholds, profits\n",
    "\n",
    "def plot_profit_model(model, costbenefit, X_train, X_test, y_train, y_test):\n",
    "    percentages = np.linspace(0, 100, len(y_test))\n",
    "    thresholds, profits = run_profit_curve(model,\n",
    "                                           costbenefit,\n",
    "                                           X_train, X_test,\n",
    "                                           y_train, y_test)\n",
    "    plt.plot(percentages, profits, label=model.__class__.__name__)\n",
    "    plt.title(\"Profit Curve\")\n",
    "    plt.xlabel(\"Percentage of test instances (decreasing by score)\")\n",
    "    plt.ylabel(\"Profit\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('profit_curve.png')\n",
    "    \n",
    "def find_best_threshold(model, costbenefit, X_train, X_test, y_train, y_test):\n",
    "    max_threshold = None\n",
    "    max_profit = None\n",
    "\n",
    "    thresholds, profits = run_profit_curve(model, costbenefit,\n",
    "                                           X_train, X_test,\n",
    "                                           y_train, y_test)\n",
    "    max_index = np.argmax(profits)\n",
    "    if profits[max_index] > max_profit:\n",
    "        max_threshold = thresholds[max_index]\n",
    "        max_profit = profits[max_index]\n",
    "    return max_threshold, max_profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.1, fit_intercept=True)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred = lr.predict(X_train)\n",
    "print(\"Training score:\")\n",
    "print(\"Accuracy of the Logistic Regression is: {}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "print(\"Precision of the Logistic Regression is: {}\".format(precision_score(y_train, y_train_pred)))\n",
    "print(\"Recall of the Logistic Regression is: {}\".format(recall_score(y_train, y_train_pred)))\n",
    "print(\"f1-score of the Logistic Regression is: {}\".format(f1_score(y_train, y_train_pred)))\n",
    "print(\"Area Under Curve (AUC) of the Logistic Regression is: {}\".format(roc_auc_score(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = lr.predict(X_test)\n",
    "print(\"Test score:\")\n",
    "print(\"Accuracy of the Logistic Regression is: {}\".format(accuracy_score(y_test, y_test_pred)))\n",
    "print(\"Precision of the Logistic Regression is: {}\".format(precision_score(y_test, y_test_pred)))\n",
    "print(\"Recall of the Logistic Regression is: {}\".format(recall_score(y_test, y_test_pred)))\n",
    "print(\"f1-score of the Logistic Regression is: {}\".format(f1_score(y_test, y_test_pred)))\n",
    "print(\"Area Under Curve (AUC) of the Logistic Regression is: {}\".format(roc_auc_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define cost-benefit matrix based on business input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "costbenefit = np.array([[20, -20], [0, 0]])\n",
    "costbenefit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot profit curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_profit_model(lr, costbenefit, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_threshold, max_profit = find_best_threshold(lr, costbenefit, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The best threshold is {}, which gives a max profit of {}\".format(max_threshold, max_profit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions on new threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = (lr.predict_proba(X_test)[:,1] >= max_threshold).astype(int)\n",
    "print(\"Test score:\")\n",
    "print(\"Accuracy of the Logistic Regression is: {}\".format(accuracy_score(y_test, y_test_pred)))\n",
    "print(\"Precision of the Logistic Regression is: {}\".format(precision_score(y_test, y_test_pred)))\n",
    "print(\"Recall of the Logistic Regression is: {}\".format(recall_score(y_test, y_test_pred)))\n",
    "print(\"f1-score of the Logistic Regression is: {}\".format(f1_score(y_test, y_test_pred)))\n",
    "print(\"Area Under Curve (AUC) of the Logistic Regression is: {}\".format(roc_auc_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## More Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "def print_scores(y_train, y_train_predict, y_test, y_test_predict):\n",
    "    \"\"\"\n",
    "    Print precision, recall, accuracy and f1 scores.\n",
    "    \"\"\"\n",
    "    train_precision = precision_score(y_train, y_train_predict) \n",
    "    train_recall = recall_score(y_train, y_train_predict)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "    train_f1 = f1_score(y_train, y_train_predict)\n",
    "\n",
    "    test_precision = precision_score(y_test, y_test_predict)\n",
    "    test_recall = recall_score(y_test, y_test_predict)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "    test_f1 = f1_score(y_test, y_test_predict)\n",
    "\n",
    "    print \"Training score:\"\n",
    "    print train_precision, train_recall, train_accuracy, train_f1\n",
    "    print \"Testing score:\"\n",
    "    print test_precision, test_recall, test_accuracy, test_f1\n",
    "    \n",
    "    df_result = pd.DataFrame(data={\"Precision\": [train_precision, test_precision], \n",
    "                                   \"Recall\": [train_recall, test_recall],\n",
    "                                   \"Accuracy\": [train_accuracy, train_f1],\n",
    "                                   \"F1-Score\": [train_f1, test_f1]}, \n",
    "                             index=[\"Training Set\", \"Testing Set\"],\n",
    "                             columns=[\"Precision\", \"Recall\", \"Accuracy\", \"F1-Score\"]\n",
    "                            )\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_predict = clf.predict(X_train)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "print_scores(y_train, y_train_predict, y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_predict = clf.predict(X_train)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "print_scores(y_train, y_train_predict, y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_predict = clf.predict(X_train)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "print_scores(y_train, y_train_predict, y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_predict = clf.predict(X_train)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "print_scores(y_train, y_train_predict, y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_importance(clf, col_names, max_features=10):\n",
    "    '''Plot feature importance'''\n",
    "    feature_importance = clf.feature_importances_\n",
    "    # make importances relative to max importance\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    \n",
    "    # Show only top features\n",
    "    pos = pos[-max_features:]\n",
    "    feature_importance = (feature_importance[sorted_idx])[-max_features:]\n",
    "    feature_names = (col_names[sorted_idx])[-max_features:]\n",
    "    \n",
    "    plt.barh(pos, feature_importance, align='center')\n",
    "    plt.yticks(pos, feature_names)\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Variable Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_importance(clf, df.columns, max_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.learning_curve as curves\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "def plt_max_features(X, y):\n",
    "    \"\"\" Calculates the performance of the model as model complexity increases.\n",
    "        The learning and testing errors rates are then plotted. \"\"\"\n",
    "    \n",
    "    # Create 10 cross-validation sets for training and testing\n",
    "    cv = ShuffleSplit(X.shape[0], n_iter=10, test_size=0.3, random_state=1)\n",
    "\n",
    "    # Vary the max_depth parameter from 1 to 10\n",
    "    features_range = np.arange(1, 12)\n",
    "\n",
    "    # Create a Random Forest classifier at optimal settings\n",
    "    clf = RandomForestClassifier(max_depth=8, n_estimators=100, random_state=1)\n",
    "  \n",
    "    # Calculate the training and testing scores\n",
    "    train_scores, test_scores = curves.validation_curve(clf, X, y, \n",
    "                                                        param_name='max_features', \n",
    "                                                        param_range=features_range, \n",
    "                                                        cv=cv, \n",
    "                                                        scoring='f1')\n",
    "\n",
    "    # Find the mean and standard deviation for smoothing\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot the validation curve\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.title('Random Forest Classifier Complexity Performance')\n",
    "    plt.plot(features_range, train_mean, 'o-', color = 'r', label = 'Training Score')\n",
    "    plt.plot(features_range, test_mean, 'o-', color = 'g', label = 'Testing Score')\n",
    "    plt.fill_between(features_range, train_mean - train_std, train_mean + train_std, alpha=0.15, color='r')\n",
    "    plt.fill_between(features_range, test_mean - test_std, test_mean + test_std, alpha=0.15, color='g')\n",
    "    \n",
    "    # Visual aesthetics\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('Maximum Features')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.ylim([0.75,0.90])\n",
    "    plt.show()\n",
    "\n",
    "def plt_max_depth(X, y):\n",
    "    \"\"\" Calculates the performance of the model as model complexity increases.\n",
    "        The learning and testing errors rates are then plotted. \"\"\"\n",
    "    \n",
    "    # Create 10 cross-validation sets for training and testing\n",
    "    cv = ShuffleSplit(X.shape[0], n_iter=10, test_size=0.3, random_state=1)\n",
    "\n",
    "    # Vary the max_depth parameter from 1 to 10\n",
    "    depth_range = np.arange(1, 12)\n",
    "\n",
    "    # Create a Random Forest classifier at optimal settings\n",
    "    clf = RandomForestClassifier(max_features=10, n_estimators=100, random_state=1)\n",
    "  \n",
    "    # Calculate the training and testing scores\n",
    "    train_scores, test_scores = curves.validation_curve(clf, X, y,\n",
    "                                                        param_name='max_depth', \n",
    "                                                        param_range=depth_range, \n",
    "                                                        cv=cv, \n",
    "                                                        scoring='f1')\n",
    "\n",
    "    # Find the mean and standard deviation for smoothing\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot the validation curve\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.title('Random Forest Classifier Complexity Performance')\n",
    "    plt.plot(depth_range, train_mean, 'o-', color = 'r', label = 'Training Score')\n",
    "    plt.plot(depth_range, test_mean, 'o-', color = 'g', label = 'Testing Score')\n",
    "    plt.fill_between(depth_range, train_mean - train_std, train_mean + train_std, alpha = 0.15, color = 'r')\n",
    "    plt.fill_between(depth_range, test_mean - test_std, test_mean + test_std, alpha = 0.15, color = 'g')\n",
    "    \n",
    "    # Visual aesthetics\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlabel('Maximum Depth')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.ylim([0.60,0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_max_features(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_max_depth(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=200, learning_rate=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_predict = clf.predict(X_train)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "print_scores(y_train, y_train_predict, y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_importance(clf, df.columns, max_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_staged_score(clf, params, X_train, y_train, X_test, y_test):\n",
    "    '''Plot training deviance. From sklearn documentation'''    \n",
    "    # compute train set accuracy score    \n",
    "    train_score = np.array(list(clf.staged_score(X_train, y_train)))\n",
    "    # compute test set accuracy score    \n",
    "    test_score = np.array(list(clf.staged_score(X_test, y_test)))\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(np.arange(params['n_estimators']) + 1, train_score, 'b-',\n",
    "             label='Training Set')\n",
    "    plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n",
    "             label='Test Set')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('Boosting Iterations')\n",
    "    plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_staged_score(clf, clf.get_params(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=500)\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_predict = clf.predict(X_train)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "print_scores(y_train, y_train_predict, y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss(clf, params, X_test, y_test):\n",
    "    '''Plot training deviance. From sklearn documentation'''    \n",
    "    # compute test set deviance\n",
    "    test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "    \n",
    "    for i, y_pred in enumerate(clf.staged_decision_function(X_test)):\n",
    "        test_score[i] = clf.loss_(y_test, y_pred)\n",
    "\n",
    "    plt.title('Deviance')\n",
    "    plt.plot(np.arange(params['n_estimators']) + 1, clf.train_score_, 'b-',\n",
    "             label='Training Set Deviance')\n",
    "    plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n",
    "             label='Test Set Deviance')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Boosting Iterations')\n",
    "    plt.ylabel(clf.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_loss(clf, clf.get_params(), X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_importance(clf, df.columns, max_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_predict = clf.predict(X_train)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "print_scores(y_train, y_train_predict, y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since all these algorithms have same sklearn API, we can pack them up and simplify our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_LRC = LogisticRegression()\n",
    "clf_KNC = KNeighborsClassifier()\n",
    "clf_RFC = RandomForestClassifier()\n",
    "clf_ABC = AdaBoostClassifier()\n",
    "clf_GBC = GradientBoostingClassifier()\n",
    "clf_SVC = SVC()\n",
    "\n",
    "models = [clf_LRC, clf_KNC, clf_RFC, clf_ABC, clf_GBC, clf_SVC]\n",
    "\n",
    "for clf in models:\n",
    "    print(\"\\n{}: \\n\".format(clf.__class__.__name__))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_train_predict = clf.predict(X_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    print(print_scores(y_train, y_train_predict, y_test, y_predict))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LogisticRegression: \n",
    "\n",
    "Training score:\n",
    "0.737689993667 0.854242104781 0.7198 0.791699411652\n",
    "Testing score:\n",
    "0.738834498834 0.844866190425 0.716266666667 0.788300835655\n",
    "\n",
    "KNeighborsClassifier: \n",
    "\n",
    "Training score:\n",
    "0.836286321758 0.865380208095 0.810485714286 0.850584551618\n",
    "Testing score:\n",
    "0.778793228788 0.799552191065 0.732666666667 0.789036195286\n",
    "\n",
    "RandomForestClassifier: \n",
    "\n",
    "Training score:\n",
    "0.991308769821 0.982857404776 0.983942857143 0.987064997238\n",
    "Testing score:\n",
    "0.80334176102 0.779187546647 0.742666666667 0.791080320416\n",
    "\n",
    "AdaBoostClassifier: \n",
    "\n",
    "Training score:\n",
    "0.806818181818 0.859146537104 0.783971428571 0.832160536305\n",
    "Testing score:\n",
    "0.804838709677 0.851263460923 0.777933333333 0.82740038344\n",
    "\n",
    "GradientBoostingClassifier: \n",
    "\n",
    "Training score:\n",
    "0.812510792609 0.862675894944 0.790314285714 0.836842222272\n",
    "Testing score:\n",
    "0.809774360012 0.853289263248 0.782933333333 0.830962516873\n",
    "\n",
    "SVC: \n",
    "\n",
    "Training score:\n",
    "0.786334325397 0.871934729798 0.772485714286 0.826925166815\n",
    "Testing score:\n",
    "0.780164489598 0.859686533746 0.7608 0.817997362281"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can look at cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "clf_LRC = LogisticRegression()\n",
    "clf_KNC = KNeighborsClassifier()\n",
    "clf_RFC = RandomForestClassifier()\n",
    "clf_ABC = AdaBoostClassifier()\n",
    "clf_GBC = GradientBoostingClassifier()\n",
    "clf_SVC = SVC()\n",
    "\n",
    "models = [clf_LRC, clf_KNC, clf_RFC, clf_ABC, clf_GBC, clf_SVC]\n",
    "\n",
    "for clf in models:\n",
    "    print \"{}:\\n\".format(clf.__class__.__name__)\n",
    "    cv_scores = cross_val_score(clf, X, y, cv=5, scoring='f1')\n",
    "    print(\"F1-score: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LogisticRegression: \n",
    "\n",
    "F1-score: 0.79 (+/- 0.01)\n",
    "\n",
    "KNeighborsClassifier: \n",
    "\n",
    "F1-score: 0.79 (+/- 0.01)\n",
    "\n",
    "RandomForestClassifier: \n",
    "\n",
    "F1-score: 0.79 (+/- 0.01)\n",
    "\n",
    "AdaBoostClassifier: \n",
    "\n",
    "F1-score: 0.83 (+/- 0.01)\n",
    "\n",
    "GradientBoostingClassifier: \n",
    "\n",
    "F1-score: 0.83 (+/- 0.00)\n",
    "\n",
    "SVC: \n",
    "\n",
    "F1-score: 0.82 (+/- 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyper-Parameters - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_LRC = LogisticRegression()\n",
    "clf_KNC = KNeighborsClassifier()\n",
    "clf_RFC = RandomForestClassifier()\n",
    "clf_ABC = AdaBoostClassifier()\n",
    "clf_GBC = GradientBoostingClassifier()\n",
    "clf_SVC = SVC()\n",
    "\n",
    "grid_LRC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'C': [1, 10, 100],\n",
    "}\n",
    "\n",
    "grid_KNC = {\n",
    "    'n_neighbors': [5, 10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "grid_RFC = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': [None, 'auto', 2, 4, 8],\n",
    "    'max_depth': [None, 2, 4, 8],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_ABC = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'learning_rate': [0.1, 0.5, 1, 5],\n",
    "}\n",
    "\n",
    "grid_GBC = {\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'max_features': [2, 4, 8],    \n",
    "    'max_depth': [2, 4, 8],\n",
    "}\n",
    "\n",
    "grid_SVC =[\n",
    "    {\n",
    "        'kernel': ['rbf'], \n",
    "        'gamma': [1e-2, 1e-3, 'auto'],\n",
    "        'C': [0.1, 1, 10]\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['linear'], \n",
    "        'C': [0.1, 1, 10]\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['poly'], \n",
    "        'degree': [2, 3],\n",
    "        'C': [0.1, 1, 10]\n",
    "    }\n",
    "]\n",
    "\n",
    "models = [clf_LRC, clf_KNC, clf_RFC, clf_ABC, clf_GBC, clf_SVC]\n",
    "grids = [grid_LRC, grid_KNC, grid_RFC, grid_ABC, grid_GBC, grid_SVC]\n",
    "\n",
    "result_models = []\n",
    "\n",
    "for clf, grid in zip(models, grids):\n",
    "    print(\"\\n{}: \\n\".format(clf.__class__.__name__))\n",
    "    print(grid)\n",
    "    grid_obj = GridSearchCV(clf, param_grid=grid, scoring='f1', n_jobs=-1)                 \n",
    "    grid_obj.fit(X_train, y_train)\n",
    "\n",
    "    result_models.append(grid_obj)\n",
    "    print(grid_obj.best_estimator_)\n",
    "    \n",
    "    y_train_predict = grid_obj.best_estimator_.predict(X_train)\n",
    "    y_test_predict = grid_obj.best_estimator_.predict(X_test)\n",
    "    print_scores(y_train, y_train_predict, y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload data from cleaned csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cleaned_data_csv = 'data/cleaned_data.csv'\n",
    "df = pd.read_csv(cleaned_data_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features = [u'avg_dist', u'avg_rating_by_driver', u'avg_rating_of_driver', u'avg_surge', \n",
    "                     u'surge_pct', u'trips_in_first_30_days', u'luxury_car_user', \n",
    "                     u'weekday_pct', u'city_Astapor', u'city_King\\'s Landing',u'city_Winterfell', \n",
    "                     u'phone_Android', u'phone_iPhone', u'phone_no_phone', u'signup_dow_0', \n",
    "                     u'signup_dow_1', u'signup_dow_2', u'signup_dow_3', u'signup_dow_4', \n",
    "                     u'signup_dow_5', u'signup_dow_6']\n",
    "target = u'churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[selected_features].values\n",
    "y = df['churn'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define metric scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "def print_scores(y_train, y_train_predict, y_test, y_test_predict):\n",
    "    \"\"\"\n",
    "    Print precision, recall, accuracy and f1 scores.\n",
    "    \"\"\"\n",
    "    train_precision = precision_score(y_train, y_train_predict) \n",
    "    train_recall = recall_score(y_train, y_train_predict)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "    train_f1 = f1_score(y_train, y_train_predict)\n",
    "\n",
    "    test_precision = precision_score(y_test, y_test_predict)\n",
    "    test_recall = recall_score(y_test, y_test_predict)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "    test_f1 = f1_score(y_test, y_test_predict)\n",
    "\n",
    "    print \"Training score:\"\n",
    "    print train_precision, train_recall, train_accuracy, train_f1\n",
    "    print \"Testing score:\"\n",
    "    print test_precision, test_recall, test_accuracy, test_f1\n",
    "    \n",
    "    df_result = pd.DataFrame(data={\"Precision\": [train_precision, test_precision], \n",
    "                                   \"Recall\": [train_recall, test_recall],\n",
    "                                   \"Accuracy\": [train_accuracy, train_f1],\n",
    "                                   \"F1-Score\": [train_f1, test_f1]}, \n",
    "                             index=[\"Training Set\", \"Testing Set\"],\n",
    "                             columns=[\"Precision\", \"Recall\", \"Accuracy\", \"F1-Score\"]\n",
    "                            )\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_predict = clf.predict(X_train)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "print(print_scores(y_train, y_train_predict, y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert sklearn model object to pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "output_model = pickle.dumps(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write pickle object to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'model.pkl'\n",
    "with open(filename, 'w') as handle:\n",
    "    handle.write(output_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read pickle object from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'model.pkl'\n",
    "with open(filename, 'r') as handle:\n",
    "    input_model = handle.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### retrieve sklearn model object from pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf2 = pickle.loads(input_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print clf2.predict(X[0:10])\n",
    "print y[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cleaned_data_csv = 'data/cleaned_data.csv'\n",
    "df = pd.read_csv(cleaned_data_csv)\n",
    "selected_features = ['avg_dist', 'avg_rating_by_driver', 'avg_rating_of_driver', 'avg_surge', \n",
    "                     'surge_pct', 'trips_in_first_30_days', 'luxury_car_user', \n",
    "                     'weekday_pct', 'city_Astapor', 'city_King\\'s Landing','city_Winterfell', \n",
    "                     'phone_Android', 'phone_iPhone', 'phone_no_phone', 'signup_dow_0', \n",
    "                     'signup_dow_1', 'signup_dow_2', 'signup_dow_3', 'signup_dow_4', \n",
    "                     'signup_dow_5', 'signup_dow_6']\n",
    "target = 'churn'\n",
    "X = df[selected_features].values\n",
    "y = df['churn'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a pipeline of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "my_estimators = [('scale', StandardScaler()),\n",
    "                 ('reduce_dim', PCA()), \n",
    "                 ('clf', LogisticRegression())]\n",
    "my_pipeline = Pipeline(my_estimators)\n",
    "my_pipeline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_pipeline.steps[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_predict = my_pipeline.predict(X_train)\n",
    "y_test_predict = my_pipeline.predict(X_test)\n",
    "print(print_scores(y_train, y_train_predict, y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "n_components = [2, 4, 6, 8, 10]\n",
    "Cs = np.logspace(-4, 4, 3)\n",
    "\n",
    "#Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "\n",
    "grid_obj = GridSearchCV(my_pipeline,\n",
    "                        param_grid=dict(reduce_dim__n_components=n_components, clf__C=Cs),\n",
    "                        scoring='f1', n_jobs=-1\n",
    "                       )\n",
    "\n",
    "grid_obj.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_obj.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_obj.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_obj.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
